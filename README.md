- ğŸ‘‹ Hi, Iâ€™m praveen 
- ğŸ‘€ Iâ€™m interested in ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ’ï¸ Iâ€™m looking to collaborate on ...
- ğŸ“« How to reach me ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...

<!--# å››ã€éšæœºåŒ– SVD

## ç¬¬ä¸€éƒ¨åˆ†ï¼šéšæœºæŠ•å½±ï¼ˆä½¿ç”¨è¯å‘é‡ï¼‰

æœ¬èŠ‚çš„ç›®çš„æ˜¯ç”¨å•è¯å‘é‡çš„å…·ä½“ä¾‹å­ï¼Œæ¥è¯´æ˜éšæœºæŠ•å½±ä¿ç•™ç»“æ„çš„æƒ³æ³•ï¼

è¦åœ¨æœºå™¨å­¦ä¹ ä¸­ä½¿ç”¨è¯­è¨€ï¼ˆä¾‹å¦‚ï¼ŒSkype ç¿»è¯‘å™¨å¦‚ä½•åœ¨è¯­è¨€ä¹‹é—´è¿›è¡Œç¿»è¯‘ï¼Œæˆ– Gmail æ™ºèƒ½å›å¤å¦‚ä½•è‡ªåŠ¨ä¸ºä½ çš„ç”µå­é‚®ä»¶å»ºè®®å¯èƒ½çš„å›å¤ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦å°†å•è¯è¡¨ç¤ºä¸ºå‘é‡ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Google çš„ Word2Vec æˆ– Stanford çš„ GloVe å°†å•è¯è¡¨ç¤ºä¸º 100 ç»´å‘é‡ã€‚ ä¾‹å¦‚ï¼Œè¿™é‡Œæ˜¯â€œpythonâ€è¿™ä¸ªè¯åœ¨ GloVe ä¸­çš„å‘é‡ï¼š

```py
vecs[wordidx['python']]

'''
array([ 0.2493,  0.6832, -0.0447, -1.3842, -0.0073,  0.651 , -0.3396,
       -0.1979, -0.3392,  0.2669, -0.0331,  0.1592,  0.8955,  0.54  ,
       -0.5582,  0.4624,  0.3672,  0.1889,  0.8319,  0.8142, -0.1183,
       -0.5346,  0.2416, -0.0389,  1.1907,  0.7935, -0.1231,  0.6642,
       -0.7762, -0.4571, -1.054 , -0.2056, -0.133 ,  0.1224,  0.8846,
        1.024 ,  0.3229,  0.821 , -0.0694,  0.0242, -0.5142,  0.8727,
        0.2576,  0.9153, -0.6422,  0.0412, -0.6021,  0.5463,  0.6608,
        0.198 , -1.1393,  0.7951,  0.4597, -0.1846, -0.6413, -0.2493,
       -0.4019, -0.5079,  0.8058,  0.5336,  0.5273,  0.3925, -0.2988,
        0.0096,  0.9995, -0.0613,  0.7194,  0.329 , -0.0528,  0.6714,
       -0.8025, -0.2579,  0.4961,  0.4808, -0.684 , -0.0122,  0.0482,
        0.2946,  0.2061,  0.3356, -0.6417, -0.6471,  0.1338, -0.1257,
       -0.4638,  1.3878,  0.9564, -0.0679, -0.0017,  0.5296,  0.4567,
        0.6104, -0.1151,  0.4263,  0.1734, -0.7995, -0.245 , -0.6089,
       -0.3847, -0.4797], dtype=float32)
'''
```

ç›®æ ‡ï¼šä½¿ç”¨éšæœºæ€§å°†æ­¤å€¼ä» 100 ç»´å‡å°‘åˆ° 20ã€‚æ£€æŸ¥ç›¸ä¼¼çš„å•è¯æ˜¯å¦ä»ç„¶ç»„åˆåœ¨ä¸€èµ·ã€‚

æ›´å¤šä¿¡æ¯ï¼šå¦‚æœä½ å¯¹è¯åµŒå…¥æ„Ÿå…´è¶£å¹¶æƒ³è¦æ›´å¤šç»†èŠ‚ï¼Œæˆ‘åœ¨[è¿™é‡Œ](https://www.youtube.com/watch?v=25nC0n9ERq4)æä¾›äº†ä¸€ä¸ªæ›´é•¿çš„å­¦ä¹ å°ç»„ï¼ˆå¸¦æœ‰[ä»£ç æ¼”ç¤º](https://github.com/fastai/word-embeddings-workshop)ï¼‰ã€‚

é£æ ¼è¯´æ˜ï¼šæˆ‘ä½¿ç”¨[å¯æŠ˜å æ ‡é¢˜](http://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/collapsible_headings/readme.html)å’Œ [jupyter ä¸»é¢˜](https://github.com/dunovank/jupyter-themes)ã€‚

### åŠ è½½æ•°æ®

```py
import pickle
import numpy as np
import re
import json

np.set_printoptions(precision=4, suppress=True)
```

è¯¥æ•°æ®é›†å¯ä»[è¿™é‡Œ](http://files.fast.ai/models/glove/6B.100d.tgz)è·å¾—ã€‚è¦ä»å‘½ä»¤è¡Œä¸‹è½½å’Œè§£å‹ç¼©æ–‡ä»¶ï¼Œä½ å¯ä»¥è¿è¡Œï¼š

```
wget http://files.fast.ai/models/glove_50_glove_100.tgz 
tar xvzf glove_50_glove_100.tgz
```

ä½ éœ€è¦æ›´æ–°ä»¥ä¸‹è·¯å¾„ï¼Œæ¥æŒ‡å®šå­˜å‚¨æ•°æ®çš„ä½ç½®ã€‚

```py
path = "../data/"

vecs = np.load(path + "glove_vectors_100d.npy")

with open(path + "words.txt") as f:
    content = f.readlines()
words = [x.strip() for x in content] 

wordidx = json.load(open(path + "wordsidx.txt"))
```

### æˆ‘ä»¬çš„æ•°æ®çš„æ ·å­

æˆ‘ä»¬æœ‰ä¸€ä¸ªå•è¯çš„é•¿åˆ—è¡¨ã€‚

```py
len(words)

# 400000

words[:10]

# ['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '"', "'s"]

words[600:610]

'''
['together',
 'congress',
 'index',
 'australia',
 'results',
 'hard',
 'hours',
 'land',
 'action',
 'higher']
'''
```

`wordidx`å…è®¸æˆ‘ä»¬æŸ¥æ‰¾å•è¯æ¥æ‰¾å‡ºå®ƒçš„ç´¢å¼•ï¼š

```py
wordidx['python']

# 20019

words[20019]

# 'python'
```

### ä½œä¸ºå‘é‡çš„å•è¯

å•è¯â€œpythonâ€ç”± 100 ç»´å‘é‡è¡¨ç¤ºï¼š

```py
vecs[wordidx['python']]

'''
array([ 0.2493,  0.6832, -0.0447, -1.3842, -0.0073,  0.651 , -0.3396,
       -0.1979, -0.3392,  0.2669, -0.0331,  0.1592,  0.8955,  0.54  ,
       -0.5582,  0.4624,  0.3672,  0.1889,  0.8319,  0.8142, -0.1183,
       -0.5346,  0.2416, -0.0389,  1.1907,  0.7935, -0.1231,  0.6642,
       -0.7762, -0.4571, -1.054 , -0.2056, -0.133 ,  0.1224,  0.8846,
        1.024 ,  0.3229,  0.821 , -0.0694,  0.0242, -0.5142,  0.8727,
        0.2576,  0.9153, -0.6422,  0.0412, -0.6021,  0.5463,  0.6608,
        0.198 , -1.1393,  0.7951,  0.4597, -0.1846, -0.6413, -0.2493,
       -0.4019, -0.5079,  0.8058,  0.5336,  0.5273,  0.3925, -0.2988,
        0.0096,  0.9995, -0.0613,  0.7194,  0.329 , -0.0528,  0.6714,
       -0.8025, -0.2579,  0.4961,  0.4808, -0.684 , -0.0122,  0.0482,
        0.2946,  0.2061,  0.3356, -0.6417, -0.6471,  0.1338, -0.1257,
       -0.4638,  1.3878,  0.9564, -0.0679, -0.0017,  0.5296,  0.4567,
        0.6104, -0.1151,  0.4263,  0.1734, -0.7995, -0.245 , -0.6089,
       -0.3847, -0.4797], dtype=float32)
'''
```

è¿™è®©æˆ‘ä»¬å¯ä»¥åšä¸€äº›æœ‰ç”¨çš„è®¡ç®—ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è·ç¦»åº¦é‡ï¼Œçœ‹åˆ°ä¸¤ä¸ªå•è¯æœ‰å¤šè¿œï¼š

```py
from scipy.spatial.distance import cosine as dist
```

è¾ƒå°çš„æ•°å­—æ„å‘³ç€ä¸¤ä¸ªå•è¯æ›´æ¥è¿‘ï¼Œè¾ƒå¤§çš„æ•°å­—æ„å‘³ç€å®ƒä»¬æ›´åŠ åˆ†å¼€ã€‚

ç›¸ä¼¼å•è¯ä¹‹é—´çš„è·ç¦»å¾ˆçŸ­ï¼š

```py
dist(vecs[wordidx["puppy"]], vecs[wordidx["dog"]])

# 0.27636240676695256

dist(vecs[wordidx["queen"]], vecs[wordidx["princess"]])

# 0.20527545040329642
```

å¹¶ä¸”æ— å…³è¯ä¹‹é—´çš„è·ç¦»å¾ˆé«˜ï¼š

```py
dist(vecs[wordidx["celebrity"]], vecs[wordidx["dusty"]])

# 0.98835787578057777

dist(vecs[wordidx["avalanche"]], vecs[wordidx["antique"]])

# 0.96211070091611983
```

### åè§

æœ‰å¾ˆå¤šåè§çš„æœºä¼šï¼š

```py
dist(vecs[wordidx["man"]], vecs[wordidx["genius"]])

# 0.50985148631697985

dist(vecs[wordidx["woman"]], vecs[wordidx["genius"]])

# 0.6897833082810727
```

æˆ‘åªæ˜¯æ£€æŸ¥äº†å‡ å¯¹è¯ä¹‹é—´çš„è·ç¦»ï¼Œå› ä¸ºè¿™æ˜¯è¯´æ˜è¿™ä¸ªæ¦‚å¿µçš„å¿«é€Ÿè€Œç®€å•çš„æ–¹å¼ã€‚ è¿™ä¹Ÿæ˜¯ä¸€ç§éå¸¸å˜ˆæ‚çš„æ–¹æ³•ï¼Œç ”ç©¶äººå‘˜ç”¨æ›´ç³»ç»Ÿçš„æ–¹å¼è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

æˆ‘åœ¨è¿™ä¸ªå­¦ä¹ å°ç»„ä¸Šæ›´æ·±å…¥åœ°è®¨è®ºäº†åè§ã€‚


### å¯è§†åŒ–

è®©æˆ‘ä»¬å¯è§†åŒ–ä¸€äº›å•è¯ï¼

æˆ‘ä»¬å°†ä½¿ç”¨ Plotlyï¼Œä¸€ä¸ªåˆ¶ä½œäº¤äº’å¼å›¾å½¢çš„ Python åº“ï¼ˆæ³¨æ„ï¼šä»¥ä¸‹æ‰€æœ‰å†…å®¹éƒ½æ˜¯åœ¨ä¸åˆ›å»ºå¸æˆ·çš„æƒ…å†µä¸‹å®Œæˆçš„ï¼Œä½¿ç”¨å…è´¹çš„ç¦»çº¿ç‰ˆ Plotlyï¼‰ã€‚

### æ–¹æ³•

```py
import plotly
import plotly.graph_objs as go    
from IPython.display import IFrame

def plotly_3d(Y, cat_labels, filename="temp-plot.html"):
    trace_dict = {}
    for i, label in enumerate(cat_labels):
        trace_dict[i] = go.Scatter3d(
            x=Y[i*5:(i+1)*5, 0],
            y=Y[i*5:(i+1)*5, 1],
            z=Y[i*5:(i+1)*5, 2],
            mode='markers',
            marker=dict(
                size=8,
                line=dict(
                    color='rgba('+ str(i*40) + ',' + str(i*40) + ',' + str(i*40) + ', 0.14)',
                    width=0.5
                ),
                opacity=0.8
            ),
            text = my_words[i*5:(i+1)*5],
            name = label
        )

    data = [item for item in trace_dict.values()]
    layout = go.Layout(
        margin=dict(
            l=0,
            r=0,
            b=0,
            t=0
        )
    )

    plotly.offline.plot({
        "data": data,
        "layout": layout,
    }, filename=filename)

def plotly_2d(Y, cat_labels, filename="temp-plot.html"):
    trace_dict = {}
    for i, label in enumerate(cat_labels):
        trace_dict[i] = go.Scatter(
            x=Y[i*5:(i+1)*5, 0],
            y=Y[i*5:(i+1)*5, 1],
            mode='markers',
            marker=dict(
                size=8,
                line=dict(
                    color='rgba('+ str(i*40) + ',' + str(i*40) + ',' + str(i*40) + ', 0.14)',
                    width=0.5
                ),
                opacity=0.8
            ),
            text = my_words[i*5:(i+1)*5],
            name = label
        )

    data = [item for item in trace_dict.values()]
    layout = go.Layout(
        margin=dict(
            l=0,
            r=0,
            b=0,
            t=0
        )
    )

    plotly.offline.plot({
        "data": data,
        "layout": layout
    }, filename=filename)
```

æ­¤æ–¹æ³•å°†æŒ‘é€‰å‡º 3 ä¸ªç»´åº¦ï¼Œæœ€èƒ½å°†æˆ‘ä»¬çš„ç±»åˆ«å½¼æ­¤åˆ†å¼€ï¼ˆå­˜å‚¨åœ¨`dist_btwn_cats`ä¸­ï¼‰ï¼ŒåŒæ—¶æœ€å°åŒ–ç»™å®šç±»åˆ«ä¸­å•è¯çš„è·ç¦»ï¼ˆå­˜å‚¨åœ¨`dist_within_cats`ä¸­ï¼‰ã€‚

```py
def get_components(data, categories, word_indices):
    num_components = 30
    pca = decomposition.PCA(n_components=num_components).fit(data.T)
    all_components = pca.components_
    centroids = {}
    print(all_components.shape)
    for i, category in enumerate(categories):
        cen = np.mean(all_components[:, i*5:(i+1)*5], axis = 1)
        dist_within_cats = np.sum(np.abs(np.expand_dims(cen, axis=1) - all_components[:, i*5:(i+1)*5]), axis=1)
        centroids[category] = cen
    dist_btwn_cats = np.zeros(num_components)
    for category1, averages1 in centroids.items():
        for category2, averages2 in centroids.items():
            dist_btwn_cats += abs(averages1 - averages2)
            clusterness = dist_btwn_cats / dist_within_cats
    comp_indices = np.argpartition(clusterness, -3)[-3:]
    return all_components[comp_indices]
```

### å‡†å¤‡æ•°æ®

è®©æˆ‘ä»¬ç»˜åˆ¶å‡ ä¸ªä¸åŒç±»åˆ«çš„å•è¯ï¼š

```py
my_words = [
            "maggot", "flea", "tarantula", "bedbug", "mosquito", 
            "violin", "cello", "flute", "harp", "mandolin",
            "joy", "love", "peace", "pleasure", "wonderful",
            "agony", "terrible", "horrible", "nasty", "failure", 
            "physics", "chemistry", "science", "technology", "engineering",
            "poetry", "art", "literature", "dance", "symphony",
           ]

categories = [
              "bugs", "music", 
              "pleasant", "unpleasant", 
              "science", "arts"
             ]
```

åŒæ ·ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨`wordidx`å­—å…¸æŸ¥æ‰¾å•è¯çš„ç´¢å¼•ï¼š

```py
my_word_indices = np.array([wordidx[word] for word in my_words])

vecs[my_word_indices].shape

# (30, 100)
```

ç°åœ¨ï¼Œæˆ‘ä»¬å°†ç»„åˆæˆ‘ä»¬çš„å•è¯ä¸æˆ‘ä»¬æ•´ä¸ªå•è¯é›†ä¸­çš„å‰ 10,000 ä¸ªå•è¯ï¼ˆå…¶ä¸­ä¸€äº›å•è¯å·²ç»å­˜åœ¨ï¼‰ï¼Œå¹¶åˆ›å»ºåµŒå…¥çŸ©é˜µã€‚

```py
embeddings = np.concatenate((vecs[my_word_indices], vecs[:10000,:]), axis=0); embeddings.shape

# (10030, 100)
```

### åœ¨ 3D ä¸­æŸ¥çœ‹å•è¯

å•è¯æœ‰ 100 ä¸ªç»´åº¦ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§åœ¨ 3D ä¸­å¯è§†åŒ–å®ƒä»¬çš„æ–¹æ³•ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æŠ€æœ¯ï¼Œå…·æœ‰è®¸å¤šåº”ç”¨ï¼ŒåŒ…æ‹¬åœ¨è¾ƒä½ç»´åº¦å¯è§†åŒ–é«˜ç»´æ•°æ®é›†ï¼

### PCA

```py
from collections import defaultdict
from sklearn import decomposition

components = get_components(embeddings, categories, my_word_indices)
plotly_3d(components.T[:len(my_words),:], categories, "pca.html")

# (30, 10030)

IFrame('pca.html', width=600, height=400)
```

### éšæœºæŠ•å½±

Johnson-Lindenstrauss å¼•ç†ï¼šï¼ˆæ¥è‡ªç»´åŸºç™¾ç§‘ï¼‰é«˜ç»´ç©ºé—´ä¸­çš„ä¸€å°ç»„ç‚¹å¯ä»¥åµŒå…¥åˆ°æ›´ä½ç»´åº¦çš„ç©ºé—´ä¸­ï¼Œä½¿ç‚¹ä¹‹é—´çš„è·ç¦»å‡ ä¹ä¿ç•™ï¼ˆä½¿ç”¨éšæœºæŠ•å½±è¯æ˜ï¼‰ã€‚

æœ‰ç”¨çš„æ˜¯ï¼Œèƒ½å¤Ÿä»¥ä¿æŒè·ç¦»çš„æ–¹å¼å‡å°‘æ•°æ®çš„ç»´åº¦ã€‚ Johnson-Lindenstrauss å¼•ç†æ˜¯è¿™ç§ç±»å‹çš„ç»å…¸ç»“æœã€‚

```py
embeddings.shape

# (10030, 100)

rand_proj = embeddings @ np.random.normal(size=(embeddings.shape[1], 40)); rand_proj.shape

# (10030, 40)

# pca = decomposition.PCA(n_components=3).fit(rand_proj.T)
# components = pca.components_
components = get_components(rand_proj, categories, my_word_indices)
plotly_3d(components.T[:len(my_words),:], categories, "pca-rand-proj.html")

# (30, 10030)

IFrame('pca-rand-proj.html', width=600, height=400)
```

## ç¬¬äºŒéƒ¨åˆ†ï¼šç”¨äºèƒŒæ™¯æ¶ˆé™¤çš„éšæœº SVD

æˆ‘ä»¬ä»Šå¤©çš„ç›®æ ‡ï¼š

![](img/surveillance3.png)

### åŠ è½½å’Œæ ¼å¼åŒ–æ•°æ®

è®©æˆ‘ä»¬ä½¿ç”¨ BMC 2012 èƒŒæ™¯æ¨¡å‹æŒ‘æˆ˜æ•°æ®é›†ä¸­çš„çœŸå®è§†é¢‘ 003ã€‚

å¯¼å…¥æ‰€éœ€çš„åº“ï¼š

```py
import imageio
imageio.plugins.ffmpeg.download()

import moviepy.editor as mpe
import numpy as np
import scipy

%matplotlib inline
import matplotlib.pyplot as plt

scale = 0.50   # è°ƒæ•´æ¯”ä¾‹æ¥æ›´æ”¹å›¾åƒçš„åˆ†è¾¨ç‡
dims = (int(240 * scale), int(320 * scale))
fps = 60      # æ¯ç§’çš„å¸§

M = np.load("movie/med_res_surveillance_matrix_60fps.npy")

print(dims, M.shape)

# (120, 160) (19200, 6000)

plt.imshow(np.reshape(M[:,140], dims), cmap='gray');
```

![](img/4-1.png)

```py
plt.figure(figsize=(12, 12))
plt.imshow(M, cmap='gray')

# <matplotlib.image.AxesImage at 0x7f601f315fd0>
```

![](img/4-2.png)

å°†æ¥ï¼Œä½ å¯ä»¥åŠ è½½å·²ä¿å­˜çš„å†…å®¹ï¼š

```py
U = np.load("U.npy")
s = np.load("s.npy")
V = np.load("V.npy")
```

`U, S, V`æ˜¯ä»€ä¹ˆæ ·å‘¢ï¼Ÿ

```py
U.shape, s.shape, V.shape

# ((19200, 6000), (6000,), (6000, 6000))
```

æ£€æŸ¥å®ƒä»¬æ˜¯`M`çš„åˆ†è§£ã€‚

```py
reconstructed_matrix = U @ np.diag(s) @ V

np.allclose(M, reconstructed_matrix)

# True
```

æ˜¯çš„ã€‚

### ç§»é™¤èƒŒæ™¯

```py
low_rank = np.expand_dims(U[:,0], 1) * s[0] * np.expand_dims(V[0,:], 0)

plt.figure(figsize=(12, 12))
plt.imshow(low_rank, cmap='gray')

# <matplotlib.image.AxesImage at 0x7f1cc3e2c9e8>
```

![](img/4-3.png)

```py
plt.imshow(np.reshape(low_rank[:,0], dims), cmap='gray');
```

![](img/4-4.png)

æˆ‘ä»¬å¦‚ä½•è·å–é‡Œé¢çš„äººï¼Ÿ

```py
plt.imshow(np.reshape(M[:,0] - low_rank[:,0], dims), cmap='gray');
```

![](img/4-5.png)

### SVD å¯¹ä¸åŒå¤§å°çš„çŸ©é˜µçš„é€Ÿåº¦

`s`æ˜¯å¯¹è§’çŸ©é˜µçš„å¯¹è§’çº¿ã€‚

```py
np.set_printoptions(suppress=True, precision=4)

import timeit
import pandas as pd

m_array = np.array([100, int(1e3), int(1e4)])
n_array = np.array([100, int(1e3), int(1e4)])

index = pd.MultiIndex.from_product([m_array, n_array], names=['# rows', '# cols'])

pd.options.display.float_format = '{:,.3f}'.format
df = pd.DataFrame(index=m_array, columns=n_array)

# %%prun
for m in m_array:
    for n in n_array:      
        A = np.random.uniform(-40,40,[m,n])  
        t = timeit.timeit('np.linalg.svd(A, full_matrices=False)', number=3, globals=globals())
        df.set_value(m, n, t)

df/3
```

|  | 100 | 1000 | 10000 |
| --- | --- | --- | --- |
| 100 | 0.006 | 0.009 | 0.043 |
| 1000 | 0.004 | 0.259 | 0.992 |
| 10000 | 0.019 | 0.984 | 218.726 |

å¾ˆå¥½ï¼ï¼ï¼ä½†æ˜¯...

ç¼ºç‚¹ï¼šè¿™çœŸçš„å¾ˆæ…¢ï¼ˆåŒæ ·ï¼Œæˆ‘ä»¬æ‘’å¼ƒäº†å¾ˆå¤šè®¡ç®—ï¼‰ã€‚

```py
%time u, s, v = np.linalg.svd(M, full_matrices=False)

'''
CPU times: user 5min 38s, sys: 1.53 s, total: 5min 40s
Wall time: 57.1 s
'''

M.shape

# (19200, 6000)
```

### éšæœºåŒ– SVD çš„æœ€ç®€å•ç‰ˆæœ¬

æƒ³æ³•ï¼šè®©æˆ‘ä»¬ä½¿ç”¨æ›´å°çš„çŸ©é˜µï¼

æˆ‘ä»¬è¿˜æ²¡æœ‰æ‰¾åˆ°æ›´å¥½çš„é€šç”¨ SVD æ–¹æ³•ï¼Œæˆ‘ä»¬åªä¼šä½¿ç”¨æˆ‘ä»¬åœ¨è¾ƒå°çŸ©é˜µä¸Šä½¿ç”¨çš„æ–¹æ³•ï¼Œè¯¥çŸ©é˜µä¸åŸå§‹çŸ©é˜µçš„èŒƒå›´å¤§è‡´ç›¸åŒã€‚

```py
def simple_randomized_svd(M, k=10):
    m, n = M.shape
    transpose = False
    if m < n:
        transpose = True
        M = M.T
        
    rand_matrix = np.random.normal(size=(M.shape[1], k))  # short side by k
    Q, _ = np.linalg.qr(M @ rand_matrix, mode='reduced')  # long side by k
    smaller_matrix = Q.T @ M                              # k by short side
    U_hat, s, V = np.linalg.svd(smaller_matrix, full_matrices=False)
    U = Q @ U_hat
    
    if transpose:
        return V.T, s.T, U.T
    else:
        return U, s, V

%time u, s, v = simple_randomized_svd(M, 10)

'''
CPU times: user 3.06 s, sys: 268 ms, total: 3.33 s
Wall time: 789 ms
'''

U_rand, s_rand, V_rand = simple_randomized_svd(M, 10)

low_rank = np.expand_dims(U_rand[:,0], 1) * s_rand[0] * np.expand_dims(V_rand[0,:], 0)

plt.imshow(np.reshape(low_rank[:,0], dims), cmap='gray');
```

![](img/4-6.png)

æˆ‘ä»¬å¦‚ä½•è·å–é‡Œé¢çš„äººï¼Ÿ

![](img/4-7.png)

### è¿™ä¸ªæ–¹æ³•åœ¨åšä»€ä¹ˆ

```py
rand_matrix = np.random.normal(size=(M.shape[1], 10))

rand_matrix.shape

# (6000, 10)

plt.imshow(np.reshape(rand_matrix[:4900,0], (70,70)), cmap='gray');
```

![](img/4-8.png)

```py
temp = M @ rand_matrix; temp.shape

# (19200, 10)

plt.imshow(np.reshape(temp[:,0], dims), cmap='gray');
```

![](img/4-9.png)

```py
plt.imshow(np.reshape(temp[:,1], dims), cmap='gray');
```

![](img/4-10.png)

```py
Q, _ = np.linalg.qr(M @ rand_matrix, mode='reduced'); Q.shape

# (19200, 10)

np.dot(Q[:,0], Q[:,1])

# -3.8163916471489756e-17

plt.imshow(np.reshape(Q[:,0], dims), cmap='gray');
```

![](img/4-11.png)

```py
plt.imshow(np.reshape(Q[:,1], dims), cmap='gray');
```

![](img/4-12.png)

```py
smaller_matrix = Q.T @ M; smaller_matrix.shape

# (10, 6000)

U_hat, s, V = np.linalg.svd(smaller_matrix, full_matrices=False)

U = Q @ U_hat

plt.imshow(np.reshape(U[:,0], dims), cmap='gray');
```

![](img/4-13.png)

```py
reconstructed_small_M = U @ np.diag(s) @ V
```

ä»¥åŠäººã€‚

```py
plt.imshow(np.reshape(M[:,0] - reconstructed_small_M[:,0], dims), cmap='gray');
```

![](img/4-14.png)

### æ—¶é—´æ¯”è¾ƒ

```py
from sklearn import decomposition
import fbpca
```

å®Œæ•´çš„ SVDï¼š

```py
%time u, s, v = np.linalg.svd(M, full_matrices=False)

'''
CPU times: user 5min 38s, sys: 1.53 s, total: 5min 40s
Wall time: 57.1 s
'''
```

æˆ‘ä»¬çš„ï¼ˆè¿‡åº¦ç®€åŒ–ï¼‰çš„`randomized_svd`ï¼š

```py
%time u, s, v = simple_randomized_svd(M, 10)

'''
CPU times: user 2.37 s, sys: 160 ms, total: 2.53 s
Wall time: 641 ms
'''
```

Sklearnï¼š

```py
%time u, s, v = decomposition.randomized_svd(M, 10)

'''
CPU times: user 19.2 s, sys: 1.44 s, total: 20.7 s
Wall time: 3.67 s
'''
```

æ¥è‡ª Facebook fbpca åº“çš„éšæœº SVDï¼š

```py
%time u, s, v = fbpca.pca(M, 10)

'''
CPU times: user 7.28 s, sys: 424 ms, total: 7.7 s
Wall time: 1.37 s
'''
```

æˆ‘ä¼šé€‰æ‹© fbpcaï¼Œå› ä¸ºå®ƒæ¯” sklearn æ›´å¿«ï¼Œæ¯”æˆ‘ä»¬ç®€å•çš„å®ç°æ›´å¥å£®ï¼Œæ›´å‡†ç¡®ã€‚

ä»¥ä¸‹æ˜¯ Facebook Research çš„ä¸€äº›ç»“æœï¼š

![](img/randomizedSVDbenchmarks.png)

### `k`å˜åŒ–ä¸‹çš„æ—¶é—´å’Œå‡†ç¡®åº¦

```py
import timeit
import pandas as pd

U_rand, s_rand, V_rand = fbpca.pca(M, 700, raw=True)
reconstructed = U_rand @ np.diag(s_rand) @ V_rand

np.linalg.norm(M - reconstructed)

# 1.1065914828881536e-07

plt.imshow(np.reshape(reconstructed[:,140], dims), cmap='gray');
```

![](img/4-15.png)

```py
pd.options.display.float_format = '{:,.2f}'.format
k_values = np.arange(100,1000,100)
df_rand = pd.DataFrame(index=["time", "error"], columns=k_values)

# df_rand = pd.read_pickle("svd_df")

for k in k_values:
    U_rand, s_rand, V_rand = fbpca.pca(M, k, raw=True)
    reconstructed = U_rand @ np.diag(s_rand) @ V_rand
    df_rand.set_value("error", k, np.linalg.norm(M - reconstructed))
    t = timeit.timeit('fbpca.pca(M, k)', number=3, globals=globals())
    df_rand.set_value("time", k, t/3)

df_rand.to_pickle("df_rand")

df_rand
```

|  | 100 | 200 | 300 | 400 | 500 | 600 | 700 | 800 | 900 | 1000 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| time | 2.07 | 2.57 | 3.45 | 6.44 | 7.99 | 9.02 | 10.24 | 11.70 | 13.30 | 10.87 |
| error | 58,997.27 | 37,539.54 | 26,569.89 | 18,769.37 | 12,559.34 | 6,936.17 | 0.00 | 0.00 | 0.00 | 0.00 |

```py
df = pd.DataFrame(index=["error"], columns=k_values)

for k in k_values:
    reconstructed = U[:,:k] @ np.diag(s[:k]) @ V[:k,:]
    df.set_value("error", k, np.linalg.norm(M - reconstructed))

df.to_pickle("df")

fig, ax1 = plt.subplots()
ax1.plot(df.columns, df_rand.loc["time"].values, 'b-', label="randomized SVD time")
ax1.plot(df.columns, np.tile([57], 9), 'g-', label="SVD time")
ax1.set_xlabel('k: # of singular values')
# Make the y-axis label, ticks and tick labels match the line color.
ax1.set_ylabel('time', color='b')
ax1.tick_params('y', colors='b')
ax1.legend(loc = 0)

ax2 = ax1.twinx()
ax2.plot(df.columns, df_rand.loc["error"].values, 'r--', label="randomized SVD error")
ax2.plot(df.columns, df.loc["error"].values, 'm--', label="SVD error")
ax2.set_ylabel('error', color='r')
ax2.tick_params('y', colors='r')
ax2.legend(loc=1)

#fig.tight_layout()
plt.show()
```

![](img/4-16.png)

### æ•°å­¦ç»†èŠ‚

### éšæœº SVD èƒŒåçš„å¤„ç†

ä¸‹é¢æ˜¯ä¸€ä¸ªè®¡ç®—æˆªæ–­ SVD çš„è¿‡ç¨‹ï¼Œåœ¨â€œ[å¸¦æœ‰éšæœºæ€§çš„æœç´¢ç»“æ„ï¼šç”¨äºæ„é€ è¿‘ä¼¼çŸ©é˜µåˆ†è§£çš„æ¦‚ç‡ç®—æ³•](https://arxiv.org/pdf/0909.4061.pdf)â€ä¸­æè¿°ï¼Œå¹¶åœ¨[æ­¤åšå®¢æ–‡ç« ](https://research.fb.com/fast-randomized-svd/)ä¸­æ€»ç»“ï¼š

1.è®¡ç®—`A`çš„è¿‘ä¼¼èŒƒå›´ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›`Q`å…·æœ‰`r`ä¸ªæ­£äº¤åˆ—ï¼Œä½¿å¾—ï¼š

![](img/tex4-1.gif)

2.æ„é€  ![](img/tex4-2.gif)ï¼Œå®ƒæ¯”è¾ƒå°`rÃ—n`ã€‚

3.é€šè¿‡æ ‡å‡†æ–¹æ³•è®¡ç®—`B`çš„ SVDï¼ˆå› ä¸º`B`å°äº`A`æ‰€ä»¥æ›´å¿«ï¼‰ï¼Œ![](img/tex4-3.gif)ã€‚

4. ç”±äºï¼š

![](img/tex4-4.gif)

å¦‚æœæˆ‘ä»¬è®¾ç½®`U = QS`ï¼Œé‚£ä¹ˆæˆ‘ä»¬æœ‰ä¸€ä¸ªä½ç§©çš„è¿‘ä¼¼å€¼ ![](img/tex4-5.gif)ã€‚

### é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•æ‰¾åˆ°`Q`ï¼ˆæ­¥éª¤ 1ï¼‰ï¼Ÿ

ä¸ºäº†ä¼°è®¡`A`çš„èŒƒå›´ï¼Œæˆ‘ä»¬å¯ä»¥åªå–ä¸€å †éšæœºå‘é‡ ![w_i](img/tex-aa38f107289d4d73d516190581397349.gif)ï¼Œæ¥æ±‚è§£ ![Aw_i](img/tex-bcdc457be3528d6871c31858dc0389d6.gif) å½¢æˆçš„å­ç©ºé—´ã€‚ æˆ‘ä»¬å¯ä»¥ç”¨ ![w_i](img/tex-aa38f107289d4d73d516190581397349.gif) ä½œä¸ºåˆ—æ¥å½¢æˆçŸ©é˜µ`W`ã€‚ ç°åœ¨ï¼Œæˆ‘ä»¬é‡‡ç”¨`AW = QR`çš„ QR åˆ†è§£ï¼Œç„¶å`Q`çš„åˆ—å½¢æˆ`AW`çš„æ ‡å‡†æ­£äº¤åŸºï¼Œè¿™æ˜¯`A`çš„èŒƒå›´ã€‚

ç”±äºä¹˜ç§¯çŸ©é˜µ`AW`çš„è¡Œæ¯”åˆ—æ›´å¤šï¼Œå› æ­¤åˆ—å¤§è‡´æ­£äº¤ã€‚ è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æ¦‚ç‡ - æœ‰å¾ˆå¤šè¡Œï¼Œåˆ—å¾ˆå°‘ï¼Œåˆ—ä¸å¯èƒ½æ˜¯çº¿æ€§ç›¸å…³çš„ã€‚

### ä¸ºä»€ä¹ˆ ![M \sim Q Q^T M](img/tex-f7d89fc326b255fea73d7fcf23dea705.gif)

æˆ‘ä»¬è¯•å›¾æ‰¾åˆ°çŸ©é˜µ`Q`ï¼Œä½¿å¾— ![M \approx  QQ^TM](img/tex-5fe8f15151faec7684f7142cafc667c4.gif)ã€‚ æˆ‘ä»¬å¯¹`M`çš„èŒƒå›´å¾ˆæ„Ÿå…´è¶£ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º`MX`ã€‚ `Q`æœ‰æ­£äº¤åˆ—ï¼Œå› æ­¤ ![Q^TQ = I](img/tex-7e08feffe0b36227e1f55eef469f5b74.gif)ï¼ˆä½† ![QQ^T](img/tex-f44ed84fd6f63e2fb0e7dd2a90a2c3a1.gif) ä¸æ˜¯`I`ï¼Œå› ä¸º`Q`æ˜¯çŸ©å½¢çš„ï¼‰ã€‚

![QR=MX \\ QQ^TQR=QQ^TMX \\ QR=QQ^TMX](img/tex-0efe901699c0a4a6b90bbe9de36c82bc.gif)

äºæ˜¯...

![MX=QQ^TMX](img/tex-81dc1e682f76d75883f68881a975919a.gif)

å¦‚æœ`X`æ˜¯å•ä½ï¼Œæˆ‘ä»¬å°±åšæˆäº†ï¼ˆä½†æ˜¯`X`ä¼šå¤ªå¤§ï¼Œæˆ‘ä»¬ä¸ä¼šå¾—åˆ°æˆ‘ä»¬æƒ³è¦çš„åŠ é€Ÿï¼‰ã€‚ åœ¨æˆ‘ä»¬çš„é—®é¢˜ä¸­ï¼Œ`X`åªæ˜¯ä¸€ä¸ªå°çš„éšæœºçŸ©é˜µã€‚ Johnson-Lindenstrauss å¼•ç†ä¸ºå…¶å·¥ä½œåŸç†æä¾›äº†ä¸€äº›ç†ç”±ã€‚

### QR åˆ†è§£

æˆ‘ä»¬ç¨åå°†æ·±å…¥äº†è§£QRåˆ†è§£ã€‚ ç°åœ¨ï¼Œä½ åªéœ€è¦çŸ¥é“`A = QR`ï¼Œå…¶ä¸­`Q`ç”±æ­£äº¤åˆ—ç»„æˆï¼Œ`R`æ˜¯ä¸Šä¸‰è§’å½¢ã€‚ Trefethen è¯´ QR åˆ†è§£æ˜¯æ•°å€¼çº¿æ€§ä»£æ•°ä¸­æœ€é‡è¦çš„æ€æƒ³ï¼ æˆ‘ä»¬ä¸€å®šä¼šå°†å›é¡¾å®ƒã€‚

æˆ‘ä»¬è¯¥å¦‚ä½•é€‰æ‹©`r`ï¼Ÿ
å‡è®¾æˆ‘ä»¬çš„çŸ©é˜µæœ‰ 100 åˆ—ï¼Œæˆ‘ä»¬æƒ³è¦`U`å’Œ`V`ä¸­çš„5åˆ—ã€‚ä¸ºäº†å®‰å…¨èµ·è§ï¼Œæˆ‘ä»¬åº”è¯¥å°†çŸ©é˜µæŠ•å½±åˆ°æ­£äº¤åŸºä¸Šï¼Œå…¶ä¸­çš„è¡Œæ•°å’Œåˆ—æ•°å¤šäº 5ï¼ˆè®©æˆ‘ä»¬ä½¿ç”¨ 15ï¼‰ã€‚ æœ€åï¼Œæˆ‘ä»¬å–`U`å’Œ`V`çš„å‰ 5 åˆ—ã€‚

å› æ­¤ï¼Œå³ä½¿æˆ‘ä»¬çš„æŠ•å½±åªæ˜¯è¿‘ä¼¼çš„ï¼Œé€šè¿‡ä½¿å®ƒæ¯”æˆ‘ä»¬éœ€è¦çš„æ›´å¤§ï¼Œæˆ‘ä»¬å¯ä»¥å¼¥è¡¥ç²¾åº¦çš„æŸå¤±ï¼ˆå› ä¸ºæˆ‘ä»¬éšååªé‡‡ç”¨äº†ä¸€ä¸ªå­é›†ï¼‰ã€‚

### è¿™ä¸éšæœºå‡æœ‰ä½•ä¸åŒ

```py
test = M @ np.random.normal(size=(M.shape[1], 2)); test.shape

# (4800, 2)
```

éšæœºå‡å€¼ï¼š

```py
plt.imshow(np.reshape(test[:,0], dims), cmap='gray');
```

![](img/4-17.png)

å‡å€¼å›¾åƒï¼š

```py
plt.imshow(np.reshape(M.mean(axis=1), dims), cmap='gray')

# <matplotlib.image.AxesImage at 0x7f83f4093fd0>
```

![](img/4-18.png)

```py
ut, st, vt = np.linalg.svd(test, full_matrices=False)

plt.imshow(np.reshape(smaller_matrix[0,:], dims), cmap='gray');
```

![](img/4-19.png)

```py
plt.imshow(np.reshape(smaller_matrix[1,:], dims), cmap='gray');
```

![](img/4-20.png)

```py
plt.imshow(np.reshape(M[:,140], dims), cmap='gray');
```

![](img/4-21.png)

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šç”¨äºä¸»ä½“å»ºæ¨¡çš„éšæœº SVD

### éšæœº SVD

æé†’ï¼šå®Œæ•´çš„ SVD å¾ˆæ…¢ã€‚ è¿™æ˜¯æˆ‘ä»¬ä½¿ç”¨ Scipy çš„ Linalg SVD è¿›è¡Œçš„è®¡ç®—ï¼š

```py
import numpy as np

vectors = np.load("topics/vectors.npy")

vectors.shape

# (2034, 26576)

%time U, s, Vh = linalg.svd(vectors, full_matrices=False)

'''
CPU times: user 27.2 s, sys: 812 ms, total: 28 s
Wall time: 27.9 s
'''

print(U.shape, s.shape, Vh.shape)

# (2034, 2034) (2034,) (2034, 26576)
```

è¿è¡Œçš„æ˜¯ï¼Œè¿˜æœ‰æ›´å¿«çš„æ–¹æ³•ï¼š

```py
%time u, s, v = decomposition.randomized_svd(vectors, 5)

'''
CPU times: user 144 ms, sys: 8 ms, total: 152 ms
Wall time: 154 ms
'''
```

SVD çš„è¿è¡Œæ—¶å¤æ‚åº¦ä¸º`O(min(m^2 n,m n^2))`ã€‚

é—®é¢˜ï¼šæˆ‘ä»¬å¦‚ä½•åŠ å¿«é€Ÿåº¦ï¼Ÿ ï¼ˆæ²¡æœ‰ SVD ç ”ç©¶çš„æ–°çªç ´çš„æƒ…å†µä¸‹ï¼‰ã€‚

æƒ³æ³•ï¼šè®©æˆ‘ä»¬ä½¿ç”¨æ›´å°çš„çŸ©é˜µï¼ˆ`n`æ›´å°ï¼‰ï¼

æˆ‘ä»¬ä¸ä½¿ç”¨`mÃ—n`çš„æ•´ä¸ªçŸ©é˜µ`A`è®¡ç®— SVDï¼Œè€Œæ˜¯ä½¿ç”¨`B = AQ`ï¼Œå®ƒåªæ˜¯`mÃ—r`ï¼Œå¹¶ä¸”`r << n`ã€‚

æˆ‘ä»¬è¿˜æ²¡æœ‰æ‰¾åˆ°æ›´å¥½çš„ SVD é€šç”¨æ–¹æ³•ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨è¾ƒå°çš„çŸ©é˜µä¸Šä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•ã€‚

```py
%time u, s, v = decomposition.randomized_svd(vectors, 5)

'''
CPU times: user 144 ms, sys: 8 ms, total: 152 ms
Wall time: 154 ms
'''

u.shape, s.shape, v.shape

# ((2034, 5), (5,), (5, 26576))

show_topics(v)

'''
['jpeg image edu file graphics images gif data',
 'jpeg gif file color quality image jfif format',
 'space jesus launch god people satellite matthew atheists',
 'jesus god matthew people atheists atheism does graphics',
 'image data processing analysis software available tools display']
'''
```

### éšæœº SVDï¼Œç¬¬äºŒç‰ˆ

```py
from scipy import linalg
```

æ–¹æ³•`randomized_range_finder`æ‰¾åˆ°ä¸€ä¸ªæ­£äº¤çŸ©é˜µï¼Œå…¶èŒƒå›´è¿‘ä¼¼äº`A`çš„èŒƒå›´ï¼ˆæˆ‘ä»¬çš„ç®—æ³•ä¸­çš„æ­¥éª¤ 1ï¼‰ã€‚ ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ LU å’Œ QR åˆ†è§£ï¼Œæˆ‘ä»¬å°†åœ¨ç¨åæ·±å…¥ä»‹ç»è¿™ä¸¤ç§åˆ†è§£ã€‚

æˆ‘ä½¿ç”¨`sklearn.extmath.randomized_svd`æºä»£ç ä½œä¸ºæŒ‡å—ã€‚

```py
# è®¡ç®—ä¸€ä¸ªæ­£äº¤çŸ©é˜µï¼Œå…¶èŒƒå›´è¿‘ä¼¼äºAçš„èŒƒå›´
# power_iteration_normalizer å¯ä»¥æ˜¯ safe_sparse_dotï¼ˆå¿«ä½†ä¸ç¨³å®šï¼‰ï¼ŒLUï¼ˆäºŒè€…ä¹‹é—´ï¼‰æˆ– QRï¼ˆæ…¢ä½†æœ€å‡†ç¡®ï¼‰
def randomized_range_finder(A, size, n_iter=5):
    Q = np.random.normal(size=(A.shape[1], size))
    
    for i in range(n_iter):
        Q, _ = linalg.lu(A @ Q, permute_l=True)
        Q, _ = linalg.lu(A.T @ Q, permute_l=True)
        
    Q, _ = linalg.qr(A @ Q, mode='economic')
    return Q
```

è¿™é‡Œæ˜¯æˆ‘ä»¬çš„éšæœº SVD æ–¹æ³•ã€‚

```py
def randomized_svd(M, n_components, n_oversamples=10, n_iter=4):
    
    n_random = n_components + n_oversamples
    
    Q = randomized_range_finder(M, n_random, n_iter)
    print(Q.shape)
    # project M to the (k + p) dimensional space using the basis vectors
    B = Q.T @ M
    print(B.shape)
    # compute the SVD on the thin matrix: (k + p) wide
    Uhat, s, V = linalg.svd(B, full_matrices=False)
    del B
    U = Q @ Uhat
    print(U.shape)
    
    return U[:, :n_components], s[:n_components], V[:n_components, :]

u, s, v = randomized_svd(vectors, 5)

'''
(2034, 15)
(15, 26576)
(2034, 15)
'''
```

### æµ‹è¯•

```py
vectors.shape

# (2034, 26576)

Q = np.random.normal(size=(vectors.shape[1], 10)); Q.shape

# (26576, 10)

Q2, _ = linalg.qr(vectors @ Q, mode='economic'); Q2.shape

# (2034, 10)

Q2.shape

# (2034, 10)
```

### æµ‹è¯•ç»“æŸ

```py
%time u, s, v = randomized_svd(vectors, 5)

'''
CPU times: user 136 ms, sys: 0 ns, total: 136 ms
Wall time: 137 ms
'''

u.shape, s.shape, v.shape

# ((2034, 5), (5,), (5, 26576))

show_topics(v)

'''
['jpeg image edu file graphics images gif data',
 'edu graphics data space pub mail 128 3d',
 'space jesus launch god people satellite matthew atheists',
 'space launch satellite commercial nasa satellites market year',
 'image data processing analysis software available tools display']
'''
```

åœ¨æ”¹å˜ä¸»é¢˜æ•°æ—¶ï¼Œå†™ä¸€ä¸ªå¾ªç¯æ¥è®¡ç®—åˆ†è§£çš„è¯¯å·®ã€‚ç»˜åˆ¶ç»“æœã€‚

### ç­”æ¡ˆ

```py
# åœ¨æ”¹å˜ä¸»é¢˜æ•°æ—¶ï¼Œå†™ä¸€ä¸ªå¾ªç¯æ¥è®¡ç®—åˆ†è§£çš„è¯¯å·®ã€‚ç»˜åˆ¶ç»“æœ

plt.plot(range(0,n*step,step), error)

# [<matplotlib.lines.Line2D at 0x7fe3f8a1b438>]
```

![](img/4-22.png)

```py
%time u, s, v = decomposition.randomized_svd(vectors, 5)

'''
CPU times: user 144 ms, sys: 8 ms, total: 152 ms
Wall time: 154 ms
'''

%time u, s, v = decomposition.randomized_svd(vectors.todense(), 5)

'''
CPU times: user 2.38 s, sys: 592 ms, total: 2.97 s
Wall time: 2.96 s
'''
```

### æ‰©å±•èµ„æº

+   [éšæœºç®—æ³•çš„æ•´ä¸ªè¯¾ç¨‹](http://www.cs.ubc.ca/~nickhar/W12/)-
Pr207/Pr207 is a âœ¨ special âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
